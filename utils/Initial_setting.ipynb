{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMtHLn6mN0AnHCpeGxG+lv7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BBBWaaLeFO5S","executionInfo":{"status":"ok","timestamp":1745754732790,"user_tz":-540,"elapsed":24997,"user":{"displayName":"hiroyuki tanabe","userId":"14704902113517717167"}},"outputId":"cd9c1284-d7eb-408d-eaaf-a30a9789bc30"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","\n","# 1. Google Driveをマウント\n","drive.mount('/content/drive')\n","\n","# 2. プロジェクトベースディレクトリを指定\n","base_dir = '/content/drive/MyDrive/Colab Notebooks/NFFA-SEM'\n","\n","# 3. 作りたいサブディレクトリリスト\n","dirs = [\n","    'data/original',\n","    'data/processed',\n","    'models',\n","    'scripts',\n","    'checkpoints',\n","    'logs',\n","    'configs',\n","    'utils'\n","]\n","\n","# 4. ディレクトリを一括作成\n","for d in dirs:\n","    path = os.path.join(base_dir, d)\n","    os.makedirs(path, exist_ok=True)\n","\n","# 5. README.mdも作っておく（空ファイル）\n","readme_path = os.path.join(base_dir, 'README.md')\n","with open(readme_path, 'w') as f:\n","    f.write('# NFFA-SEM\\n\\nProject description here.')\n"]},{"cell_type":"code","source":["# 6. .gitignore作成\n","gitignore_path = os.path.join(base_dir, '.gitignore')\n","gitignore_content = \"\"\"\n","# Python関連\n","__pycache__/\n","*.py[cod]\n","*.so\n","\n","# 仮想環境\n","venv/\n","env/\n","ENV/\n","*.egg-info/\n","\n","# Jupyter Notebookチェックポイント\n",".ipynb_checkpoints/\n","\n","# データ・チェックポイント\n","data/original/\n","data/processed/\n","checkpoints/\n","logs/\n","\n","# モデル保存ファイル\n","*.pth\n","*.pt\n","*.h5\n","\n","# 設定ファイルの一時保存ファイル\n","*.yaml~\n","*.json~\n","\n","# IDE関連（VSCode, PyCharmなど）\n",".vscode/\n",".idea/\n","\n","# Mac特有の隠しファイル\n",".DS_Store\n","\n","# Google Colab特有\n","/content/\n","\n","# その他一時ファイル\n","*.log\n","*.tmp\n","*.bak\n","\"\"\"\n","\n","with open(gitignore_path, 'w') as f:\n","    f.write(gitignore_content.strip())\n","\n","print(\"✅ プロジェクトディレクトリと .gitignore を作成しました！\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdZkikrQHAwt","executionInfo":{"status":"ok","timestamp":1745755069308,"user_tz":-540,"elapsed":45,"user":{"displayName":"hiroyuki tanabe","userId":"14704902113517717167"}},"outputId":"d0e8e7a4-6409-41ac-f6c7-5410fccdc7cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ プロジェクトディレクトリと .gitignore を作成しました！\n"]}]},{"cell_type":"code","source":["# 7. scripts/train.py を作成（config.yaml参照）\n","train_script_path = os.path.join(base_dir, 'scripts', 'train.py')\n","train_script_content = \"\"\"\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms, models\n","import os\n","import yaml\n","\n","# ------------------------------\n","# Configファイルの読み込み\n","# ------------------------------\n","config_path = '../configs/config.yaml'\n","\n","with open(config_path) as f:\n","    config = yaml.safe_load(f)\n","\n","batch_size = config['train']['batch_size']\n","epochs = config['train']['epochs']\n","learning_rate = config['train']['learning_rate']\n","model_name = config['train']['model_name']\n","\n","train_dir = config['data']['train_dir']\n","val_dir = config['data']['val_dir']\n","checkpoint_dir = config['save']['checkpoint_dir']\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ------------------------------\n","# データセット読み込み\n","# ------------------------------\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n","val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# ------------------------------\n","# モデル準備\n","# ------------------------------\n","if model_name == 'resnet18':\n","    model = models.resnet18(pretrained=True)\n","    model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))\n","else:\n","    raise ValueError(f\"Unsupported model: {model_name}\")\n","\n","model = model.to(device)\n","\n","# 損失関数と最適化手法\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# ------------------------------\n","# 学習ループ\n","# ------------------------------\n","for epoch in range(epochs):\n","    model.train()\n","    running_loss = 0.0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n","\n","# ------------------------------\n","# モデル保存\n","# ------------------------------\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","save_path = os.path.join(checkpoint_dir, 'best_model.pth')\n","torch.save(model.state_dict(), save_path)\n","print(f\"✅ モデル保存完了！ 保存先: {save_path}\")\n","\"\"\"\n","with open(train_script_path, 'w') as f:\n","    f.write(train_script_content.strip())\n","\n","print(\"✅ プロジェクトディレクトリ＋初期スクリプトを作成しました！\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDxqgJxhHFqD","executionInfo":{"status":"ok","timestamp":1745755856746,"user_tz":-540,"elapsed":40,"user":{"displayName":"hiroyuki tanabe","userId":"14704902113517717167"}},"outputId":"4d75568e-827b-4173-c73d-85e5a3b87ba6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ プロジェクトディレクトリ＋初期スクリプトを作成しました！\n"]}]},{"source":["# configs/config.yaml\n","config_path = os.path.join(base_dir, 'configs', 'config.yaml') # Changed 'config' to 'configs'\n","config_content = \"\"\"\n","train:\n","  batch_size: 32\n","  epochs: 10\n","  learning_rate: 0.001\n","  model_name: resnet18\n","\n","data:\n","  train_dir: ../data/processed/train\n","  val_dir: ../data/processed/val\n","\n","save:\n","  checkpoint_dir: ../checkpoints\n","\"\"\"\n","with open(config_path, 'w') as f:\n","    f.write(config_content.strip())\n","\n","print(\"✅ config.yamlを作成しました！\")"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8GcdAAtXJhAI","executionInfo":{"status":"ok","timestamp":1745755762487,"user_tz":-540,"elapsed":18,"user":{"displayName":"hiroyuki tanabe","userId":"14704902113517717167"}},"outputId":"1ae1b296-1543-4560-b34d-abb05b1cc775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ config.yamlを作成しました！\n"]}]},{"cell_type":"code","source":["# 7. scripts/train.py を作成（tensorBoard版）\n","train_script_path = os.path.join(base_dir, 'scripts', 'train2.py')\n","train_script_content = \"\"\"\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms, models\n","import os\n","import yaml\n","from torch.utils.tensorboard import SummaryWriter\n","\n","# ------------------------------\n","# Configファイルの読み込み\n","# ------------------------------\n","config_path = '../configs/config.yaml'\n","\n","with open(config_path) as f:\n","    config = yaml.safe_load(f)\n","\n","batch_size = config['train']['batch_size']\n","epochs = config['train']['epochs']\n","learning_rate = config['train']['learning_rate']\n","model_name = config['train']['model_name']\n","\n","train_dir = config['data']['train_dir']\n","val_dir = config['data']['val_dir']\n","checkpoint_dir = config['save']['checkpoint_dir']\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","# ------------------------------\n","# データセット読み込み\n","# ------------------------------\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n","\n","train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n","val_dataset = datasets.ImageFolder(val_dir, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","# ------------------------------\n","# モデル準備\n","# ------------------------------\n","if model_name == 'resnet18':\n","    model = models.resnet18(pretrained=True)\n","    model.fc = nn.Linear(model.fc.in_features, len(train_dataset.classes))\n","else:\n","    raise ValueError(f\"Unsupported model: {model_name}\")\n","\n","model = model.to(device)\n","\n","# 損失関数と最適化手法\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","# ------------------------------\n","# TensorBoardライター作成\n","# ------------------------------\n","log_dir = '../logs'\n","os.makedirs(log_dir, exist_ok=True)\n","writer = SummaryWriter(log_dir=log_dir)\n","\n","# ------------------------------\n","# 学習ループ\n","# ------------------------------\n","for epoch in range(epochs):\n","    # 学習モード\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","    for inputs, labels in train_loader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = outputs.max(1)\n","        total += labels.size(0)\n","        correct += predicted.eq(labels).sum().item()\n","\n","    train_loss = running_loss / len(train_loader)\n","    train_acc = correct / total\n","\n","    # ------------------------------\n","    # バリデーション\n","    # ------------------------------\n","    model.eval()\n","    val_loss = 0.0\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for inputs, labels in val_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item()\n","            _, predicted = outputs.max(1)\n","            total += labels.size(0)\n","            correct += predicted.eq(labels).sum().item()\n","\n","    val_loss /= len(val_loader)\n","    val_acc = correct / total\n","\n","    # ------------------------------\n","    # ログ出力\n","    # ------------------------------\n","    print(f\"Epoch [{epoch+1}/{epochs}] Train Loss: {train_loss:.4f} Val Loss: {val_loss:.4f} Train Acc: {train_acc:.4f} Val Acc: {val_acc:.4f}\")\n","    writer.add_scalar('Loss/Train', train_loss, epoch)\n","    writer.add_scalar('Loss/Validation', val_loss, epoch)\n","    writer.add_scalar('Accuracy/Train', train_acc, epoch)\n","    writer.add_scalar('Accuracy/Validation', val_acc, epoch)\n","\n","# ------------------------------\n","# モデル保存\n","# ------------------------------\n","os.makedirs(checkpoint_dir, exist_ok=True)\n","save_path = os.path.join(checkpoint_dir, 'best_model.pth')\n","torch.save(model.state_dict(), save_path)\n","print(f\"✅ モデル保存完了！ 保存先: {save_path}\")\n","\n","# ------------------------------\n","# TensorBoardライター閉じる\n","# ------------------------------\n","writer.close()\n","\"\"\"\n","with open(train_script_path, 'w') as f:\n","    f.write(train_script_content.strip())\n","\n","print(\"✅ TensorBoard版train2.pyを作成しました！\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uItaUk4nJDn0","executionInfo":{"status":"ok","timestamp":1745756116269,"user_tz":-540,"elapsed":46,"user":{"displayName":"hiroyuki tanabe","userId":"14704902113517717167"}},"outputId":"3ab72270-dc31-4a97-af7f-494f4e1b5b64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ プロジェクトディレクトリ＋初期スクリプトを作成しました！\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"AJducjZTKxjg"},"execution_count":null,"outputs":[]}]}